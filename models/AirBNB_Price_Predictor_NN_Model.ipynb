{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirBNB Price Predictor 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLGq4oSHnfQd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "91759a5b-5818-4017-8402-fb57169b17dd"
      },
      "source": [
        "!pip install category_encoders"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.12.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.15.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tQTvBBamuFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow as tf\n",
        "import category_encoders as ce\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXU3j3L2m3w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/train.csv\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5nYCaDk0pbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_zipcode(X):\n",
        "  \"\"\"Extracts first 5 characters from string\"\"\"\n",
        "  return X[:5] "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2o6Kb12Gp5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def enumerate_amenities(X):\n",
        "  \"\"\"Returns sum of number of amenities\"\"\"\n",
        "  return len(X[\"amenities\"].split(\",\"))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciVA8zikF2bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def wrangle(X):\n",
        "  \"\"\"\n",
        "  Wrangles and cleans dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  # Prevent Setting With Copy warning\n",
        "  X = X.copy()\n",
        "\n",
        "  \"\"\"\n",
        "  Converting X[\"amenities\"] to countable list, replacing set of amenities\n",
        "  with count of amenities\n",
        "  \"\"\"\n",
        "  X[\"amenities\"] = X.apply(enumerate_amenities, axis=1)\n",
        "\n",
        "  # Filtering dataframe\n",
        "  X = X.filter([\"log_price\", \"property_type\", \"amenities\", \"room_type\",  \n",
        "                \"accommodates\", \"bathrooms\", \"cancellation_policy\", \n",
        "                \"cleaning_fee\", \"instant_bookable\", \"zipcode\", \"bedrooms\", \n",
        "                \"beds\"], axis=1)\n",
        "  \n",
        "  \"\"\"\n",
        "  Converting property_type to include manageable number of options for\n",
        "  ordinal encoding\n",
        "  \"\"\"\n",
        "\n",
        "  X[\"property_type\"] = X[\"property_type\"].replace(np.nan, \"Other\")\n",
        "  apartment = X[\"property_type\"].str.contains(\"Apartment\")\n",
        "  house = X[\"property_type\"].str.contains(\"House\")\n",
        "  loft = X[\"property_type\"].str.contains(\"Loft\")\n",
        "  hostel = X[\"property_type\"].str.contains(\"Hostel\")\n",
        "  condo = X[\"property_type\"].str.contains(\"Condominium\")\n",
        "  townhouse = X[\"property_type\"].str.contains(\"Townhouse\")\n",
        "  earth_house = X[\"property_type\"].str.contains(\"Earth House\")\n",
        "  othr_conditional = ~apartment & ~house & ~loft & ~hostel & ~condo & ~townhouse\n",
        "  X.loc[earth_house, \"property_type\"] = \"Other\"\n",
        "  X.loc[othr_conditional, \"property_type\"] = \"Other\"\n",
        "\n",
        "  # Cleaning zipcode column, extracting zip code\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].replace(\"Near 91304\", 91304)\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].replace(\"1m\", 10023)\n",
        "  X[\"zipcode\"] = pd.to_numeric(X[\"zipcode\"], errors=\"coerce\")\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].replace(np.nan, X[\"zipcode\"].median())\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].astype(str)\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].apply(extract_zipcode)\n",
        "  X[\"zipcode\"] = X[\"zipcode\"].replace(\".\", \"\")  \n",
        "  X[\"zipcode\"] = X[\"zipcode\"].astype(float)\n",
        "\n",
        "  # Replacing NaN values with median\n",
        "  X[\"bathrooms\"] = X[\"bathrooms\"].replace(np.nan, X[\"bathrooms\"].median())\n",
        "  X[\"bedrooms\"] = X[\"bedrooms\"].replace(np.nan, X[\"bedrooms\"].median())\n",
        "  X[\"beds\"] = X[\"beds\"].replace(np.nan, X[\"beds\"].median())\n",
        "\n",
        "  # Encoding categorical variables\n",
        "  encoder = ce.OrdinalEncoder()\n",
        "  X = encoder.fit_transform(X)\n",
        "\n",
        "  # Converting data to integers for seamless entry into neural network\n",
        "  X = X.astype(float)\n",
        "\n",
        "  return X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e30K3smFIP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Applying wrangle function\n",
        "\n",
        "df = wrangle(df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJA8KLnZFAOr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data set into training and test sets\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=7)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdoWKNiBH1eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting train and test sets into X feature matrix and y target vector\n",
        "\n",
        "target = \"log_price\"\n",
        "\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "\n",
        "X_test = test.drop(columns=target)\n",
        "y_test = test[target]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LF_z6Qvn7_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building neural network architecture\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(512, input_dim=11, activation= 'relu'),\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dense(64, activation='swish'),\n",
        "    Dense(32, activation='swish'),\n",
        "    Dense(16, activation='swish'),\n",
        "    Dense(1, activation = 'linear')\n",
        "    ])\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EY1qYuCTvCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98005f2f-fb90-4b6f-f122-0f056de094c3"
      },
      "source": [
        "# Fitting NN to data\n",
        "\n",
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=50, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3310 - val_loss: 0.2678\n",
            "Epoch 2/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.3218 - val_loss: 0.2968\n",
            "Epoch 3/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3077 - val_loss: 0.2944\n",
            "Epoch 4/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3050 - val_loss: 0.3040\n",
            "Epoch 5/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3037 - val_loss: 0.3236\n",
            "Epoch 6/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3023 - val_loss: 0.2962\n",
            "Epoch 7/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2949 - val_loss: 0.2605\n",
            "Epoch 8/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2957 - val_loss: 0.4075\n",
            "Epoch 9/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.3000 - val_loss: 0.2848\n",
            "Epoch 10/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2896 - val_loss: 0.2633\n",
            "Epoch 11/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2901 - val_loss: 0.2569\n",
            "Epoch 12/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2902 - val_loss: 0.2591\n",
            "Epoch 13/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2858 - val_loss: 0.2508\n",
            "Epoch 14/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2871 - val_loss: 0.2636\n",
            "Epoch 15/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2856 - val_loss: 0.2591\n",
            "Epoch 16/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2864 - val_loss: 0.2598\n",
            "Epoch 17/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2854 - val_loss: 0.3355\n",
            "Epoch 18/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2838 - val_loss: 0.2460\n",
            "Epoch 19/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2830 - val_loss: 0.2665\n",
            "Epoch 20/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2857 - val_loss: 0.2592\n",
            "Epoch 21/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2820 - val_loss: 0.2466\n",
            "Epoch 22/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2801 - val_loss: 0.2648\n",
            "Epoch 23/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2822 - val_loss: 0.2529\n",
            "Epoch 24/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2751 - val_loss: 0.2489\n",
            "Epoch 25/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2831 - val_loss: 0.2679\n",
            "Epoch 26/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2766 - val_loss: 0.2495\n",
            "Epoch 27/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2811 - val_loss: 0.2510\n",
            "Epoch 28/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2794 - val_loss: 0.3631\n",
            "Epoch 29/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2752 - val_loss: 0.2531\n",
            "Epoch 30/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2747 - val_loss: 0.2739\n",
            "Epoch 31/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2741 - val_loss: 0.2460\n",
            "Epoch 32/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2774 - val_loss: 0.2551\n",
            "Epoch 33/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2695 - val_loss: 0.2553\n",
            "Epoch 34/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2715 - val_loss: 0.2680\n",
            "Epoch 35/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2768 - val_loss: 0.2547\n",
            "Epoch 36/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2724 - val_loss: 0.2758\n",
            "Epoch 37/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2740 - val_loss: 0.2487\n",
            "Epoch 38/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2711 - val_loss: 0.2523\n",
            "Epoch 39/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2714 - val_loss: 0.3161\n",
            "Epoch 40/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2774 - val_loss: 0.2499\n",
            "Epoch 41/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2733 - val_loss: 0.2421\n",
            "Epoch 42/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2734 - val_loss: 0.2483\n",
            "Epoch 43/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2718 - val_loss: 0.2800\n",
            "Epoch 44/50\n",
            "1853/1853 [==============================] - 8s 5ms/step - loss: 0.2674 - val_loss: 0.2404\n",
            "Epoch 45/50\n",
            "1853/1853 [==============================] - 8s 4ms/step - loss: 0.2683 - val_loss: 0.2521\n",
            "Epoch 46/50\n",
            "1853/1853 [==============================] - 9s 5ms/step - loss: 0.2701 - val_loss: 0.2488\n",
            "Epoch 47/50\n",
            "1853/1853 [==============================] - 10s 5ms/step - loss: 0.2663 - val_loss: 0.3157\n",
            "Epoch 48/50\n",
            "1853/1853 [==============================] - 11s 6ms/step - loss: 0.2711 - val_loss: 0.2787\n",
            "Epoch 49/50\n",
            "1853/1853 [==============================] - 11s 6ms/step - loss: 0.2683 - val_loss: 0.2546\n",
            "Epoch 50/50\n",
            "1853/1853 [==============================] - 10s 6ms/step - loss: 0.2676 - val_loss: 0.2577\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb65c562320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQlY6NReMiON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_price(X):\n",
        "  \"\"\"\n",
        "  Uses model to predict price based on inputted features\n",
        "  \"\"\"\n",
        "  return math.exp(model.predict(X))\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9is1kbwCz9WY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Calculate MSE. Try different models, probably Random Forest\n",
        "\n",
        "# all_output = model.predict(X_train)\n",
        "# error_all = (y_train - all_output) / len(X_train)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1McLbH9Dvab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ec47f188-a1a0-4627-dd05-4189a6c72af5"
      },
      "source": [
        "# Saving weights and architecture of NN\n",
        "\n",
        "model.save(\"airbnb_NN\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: airbnb_NN/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQe9zZsUV6St",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "6f475429-90e3-4958-9d29-90bd1358f8e1"
      },
      "source": [
        "# Recreating model as a sanity check\n",
        "\n",
        "reconstructed_model = tf.keras.models.load_model(\"/content/drive/My Drive/airbnb_NN/\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_239621) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_dense_5_layer_call_and_return_conditional_losses_239050) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_dense_3_layer_call_and_return_conditional_losses_238986) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference__wrapped_model_238885) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference__wrapped_model_238885) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference__wrapped_model_238885) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239387) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239387) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239387) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_dense_5_layer_call_and_return_conditional_losses_239646) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_dense_4_layer_call_and_return_conditional_losses_239018) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239454) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239454) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_sequential_layer_call_and_return_conditional_losses_239454) with ops with custom gradients. Will likely fail if a gradient is requested.\n",
            "WARNING:tensorflow:Importing a function (__inference_dense_3_layer_call_and_return_conditional_losses_239596) with ops with custom gradients. Will likely fail if a gradient is requested.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTwKRHenWmk8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eee03cb7-cc99-424a-a9ce-516fd1bddd40"
      },
      "source": [
        "# Checking if reconstructed_model makes predictions\n",
        "\n",
        "z = [[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]\n",
        "\n",
        "math.exp(reconstructed_model.predict(z))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127.6150835751411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah9EaeWTZpwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
